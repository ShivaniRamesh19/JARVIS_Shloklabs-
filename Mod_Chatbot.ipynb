{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d86034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import json\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c2ae31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = {\n",
    "  \"intents\": [\n",
    "    {\n",
    "      \"tag\": \"greeting\",\n",
    "      \"patterns\": [\"Hi\", \"Hello\", \"Hey\", \"Good day\", \"How are you?\"],\n",
    "      \"responses\": [\"Hello!\", \"Good to see you!\", \"Hi there, how can I help?\"],\n",
    "    },\n",
    "    {\n",
    "      \"tag\": \"farewell\",\n",
    "      \"patterns\": [\"Goodbye\", \"Bye\", \"See you later\", \"Talk to you later\"],\n",
    "      \"responses\": [\"Sad to see you go :(\", \"Goodbye!\", \"Come back soon!\"],\n",
    "\n",
    "    },\n",
    "    {\n",
    "      \"tag\": \"creator\",\n",
    "      \"patterns\": [\"Who created you?\", \"Who is your developer?\", \"Who made you?\"],\n",
    "      \"responses\": [\"I was created by Shivani & Arthiga\"]\n",
    "\n",
    "    },\n",
    "    {\n",
    "      \"tag\": \"identity\",\n",
    "      \"patterns\": [\"What is your name?\", \"What should I call you?\", \"Who are you?\",\"What are you\",\"Introduce Yourself\"],\n",
    "      \"responses\": [\"You can call me Jarvis. I'm a Chatbot.\"]\n",
    "\n",
    "    },\n",
    "    \n",
    "    {\n",
    "      \"tag\": \"casual_greeting\",\n",
    "      \"patterns\": [\"What's up?\", \"How are you?\", \"How you doing?\"],\n",
    "       \"responses\": [\"I'm here to assist you with any questions or information you need. How can I assist you today?\"]\n",
    "\n",
    "     },\n",
    "    {\n",
    "      \"tag\": \"good_morning\",\n",
    "      \"patterns\": [\"Good morning\", \"Morning\"],\n",
    "      \"responses\": [\"Good morning! How can I assist you today?\"]\n",
    "\n",
    "     },\n",
    "     {\n",
    "       \"tag\": \"good_afternoon\",\n",
    "       \"patterns\": [\"Good afternoon\", \"Afternoon\"],\n",
    "        \"responses\": [\"Good afternoon! How can I assist you today?\"]\n",
    "\n",
    "      },\n",
    "      {\n",
    "      \"tag\": \"good_evening\",\n",
    "      \"patterns\": [\"Good evening\", \"Evening\"],\n",
    "       \"responses\": [\"Good evening! How can I assist you today?\"]\n",
    "\n",
    "         },\n",
    "          {\n",
    "        \"tag\": \"thank_you\",\n",
    "        \"patterns\": [\"Thank you\", \"Thanks\"],\n",
    "        \"responses\": [\"You're welcome! If you have any more questions, feel free to ask.\"]\n",
    "\n",
    "        },\n",
    "       {\n",
    "       \"tag\": \"sorry\",\n",
    "      \"patterns\": [\"Sorry\", \"Apologies\"],\n",
    "       \"responses\": [\"No problem! If there's anything else you need assistance with, feel free to let me know.\"]\n",
    "\n",
    "    },\n",
    "    {\n",
    "         \"tag\": \"Total_Failures\",\n",
    "      \"patterns\": [\"Total Failures\",\"Today count of machine failure?\",\"How many machines failed?\"],\n",
    "       \"responses\": [\"Here are the results!\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"Total_Non_Failures\",\n",
    "      \"patterns\": [\"Total Avalible machines\",\"Today count of machine present?\",\"How many machines available?\"],\n",
    "       \"responses\": [\"Here are the results!\"]\n",
    "    }  ,\n",
    "    { \"tag\": \"Common_Failure_Conditions\",\n",
    "      \"patterns\": [\"what are the conditions for failure\",\"common failure conditions?\"],\n",
    "       \"responses\": [\"Here are the results!\"]\n",
    "        \n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"Average_Temperature\",\n",
    "      \"patterns\": [\"what is the average temperature for failure\",\"Average Temperature for failure\"],\n",
    "       \"responses\": [\"Here are the results!\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"High_VOC\",\n",
    "      \"patterns\": [\"what is the Failure Rate with High VOC \"],\n",
    "       \"responses\": [\"Here are the results!\"]\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"High_Footfall\",\n",
    "      \"patterns\": [\"what is the Failure Rate with High Footfall? \"],\n",
    "       \"responses\": [\"Here are the results!\"]\n",
    "    },\n",
    "  {\n",
    "       \"tag\": \"CS_Level\",\n",
    "      \"patterns\": [\"what is the Failure Rate with CS Level? \"],\n",
    "       \"responses\": [\"Here are the results!\"]\n",
    "  },\n",
    "  {\n",
    "       \"tag\": \"Poor_Air_Quality \",\n",
    "      \"patterns\": [\"what is the Failure Rate with Poor Air Quality ? \"],\n",
    "       \"responses\": [\"Here are the results!\"]\n",
    "  },\n",
    "  {\n",
    "       \"tag\": \"High_IP\",\n",
    "      \"patterns\": [\"what is the Failure Rate with High IP? \"],\n",
    "       \"responses\": [\"Here are the results!\"]\n",
    "  }\n",
    "]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "139cd27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rockstar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec3d7c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform synonym replacement\n",
    "def synonym_replacement(tokens, limit):\n",
    "    augmented_sentences = []\n",
    "    for i in range(len(tokens)):\n",
    "        synonyms = []\n",
    "        for syn in wordnet.synsets(tokens[i]):\n",
    "            for lemma in syn.lemmas():\n",
    "                synonyms.append(lemma.name())\n",
    "        if len(synonyms) > 0:\n",
    "            num_augmentations = min(limit, len(synonyms))\n",
    "            sampled_synonyms = random.sample(synonyms, num_augmentations)\n",
    "            for synonym in sampled_synonyms:\n",
    "                augmented_tokens = tokens[:i] + [synonym] + tokens[i+1:]\n",
    "                augmented_sentences.append(' '.join(augmented_tokens))\n",
    "    return augmented_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b97213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "717\n",
      "717\n"
     ]
    }
   ],
   "source": [
    "text_data = []\n",
    "labels = []\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "limit_per_tag = 40\n",
    "\n",
    "for intent in intents['intents']:\n",
    "    augmented_sentences_per_tag = 0\n",
    "    for example in intent['patterns']:\n",
    "        tokens = nltk.word_tokenize(example.lower())\n",
    "        filtered_tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stopwords and token.isalpha()]\n",
    "        if filtered_tokens:\n",
    "            text_data.append(' '.join(filtered_tokens))\n",
    "            labels.append(intent['tag'])\n",
    "            \n",
    "            augmented_sentences = synonym_replacement(filtered_tokens, limit_per_tag - augmented_sentences_per_tag)\n",
    "            for augmented_sentence in augmented_sentences:\n",
    "                text_data.append(augmented_sentence)\n",
    "                labels.append(intent['tag'])\n",
    "                augmented_sentences_per_tag += 1\n",
    "                if augmented_sentences_per_tag >= limit_per_tag:\n",
    "                    break\n",
    "\n",
    "print(len(text_data))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85d546f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(text_data)\n",
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcb2ea4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(X, y, test_size=0.2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=100)\n",
    "\n",
    "\n",
    "    models = [\n",
    "        ('Logistic Regression', LogisticRegression(), {\n",
    "            'penalty': ['l2'],\n",
    "            'C': [0.1, 1.0, 10.0],\n",
    "            'solver': ['liblinear'],\n",
    "            'max_iter': [100, 1000, 10000]\n",
    "        }),\n",
    "        ('Multinomial Naive Bayes', MultinomialNB(), {'alpha': [0.1, 0.5, 1.0]}),\n",
    "        ('Linear SVC', LinearSVC(), {\n",
    "            'penalty': ['l2'],\n",
    "            'loss': ['hinge', 'squared_hinge'],\n",
    "            'C': [0.1, 1, 10],\n",
    "            'max_iter': [100, 1000, 10000]\n",
    "        }),\n",
    "        ('Decision Tree', DecisionTreeClassifier(), {\n",
    "            'max_depth': [5, 10, 20, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'criterion': ['gini', 'entropy']\n",
    "        }),\n",
    "        ('Random Forest', RandomForestClassifier(), {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [10, 20, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        })\n",
    "    ]\n",
    "\n",
    "    for name, model, param_grid in models:\n",
    "        grid = GridSearchCV(model, param_grid, cv=3, n_jobs=-1)\n",
    "        grid.fit(X_train, y_train)\n",
    "        y_pred = grid.predict(X_test)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        print(f'{name}: {score:.4f} (best parameters: {grid.best_params_})')\n",
    "\n",
    "    best_model = max(models, key=lambda x: GridSearchCV(x[1], x[2], cv=3, n_jobs=-1).fit(X_train, y_train).score(X_test, y_test))\n",
    "    print(f'\\nBest model: {best_model[0]}')\n",
    "\n",
    "    # Fit the best model to the full training data\n",
    "    best_model[1].fit(X, y)\n",
    "\n",
    "    return best_model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47e04ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.9048 (best parameters: {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear'})\n",
      "Multinomial Naive Bayes: 0.4656 (best parameters: {'alpha': 0.1})\n",
      "Linear SVC: 0.8995 (best parameters: {'C': 1, 'loss': 'hinge', 'max_iter': 10000, 'penalty': 'l2'})\n",
      "Decision Tree: 0.9206 (best parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 5})\n",
      "Random Forest: 0.9153 (best parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100})\n",
      "\n",
      "Best model: Decision Tree\n"
     ]
    }
   ],
   "source": [
    "best_model = find_best_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07a2d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aaed4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   footfall  tempMode  AQ  USS  CS  VOC  RP  IP  Temperature  fail\n",
      "0         0         7   7    1   6    6  36   3            1     1\n",
      "1       190         1   3    3   5    1  20   4            1     0\n",
      "2        31         7   2    2   6    1  24   6            1     0\n",
      "3        83         4   3    4   5    1  28   6            1     0\n",
      "4       640         7   5    6   4    0  68   6            1     0\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('data.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ff708bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Assuming the target variable is 'fail' and features include the sensor readings and other metrics\n",
    "X = df.drop('fail', axis=1)  # Feature variables\n",
    "y = df['fail']  # Target variable (machine failure)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model (using GradientBoostingClassifier as an example)\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Functions to answer specific questions\n",
    "\n",
    "# 1. Total count of machine failures\n",
    "def total_failures():\n",
    "    return df['fail'].sum()\n",
    "\n",
    "# 2. Total count of machines that did not fail\n",
    "def total_non_failures():\n",
    "    return (df['fail'] == 0).sum()\n",
    "\n",
    "# 3. Most common sensor readings associated with machine failure\n",
    "def common_failure_conditions():\n",
    "    failure_conditions = df[df['fail'] == 1].mode().iloc[0]\n",
    "    return failure_conditions.to_dict()\n",
    "\n",
    "# 4. Average temperature at the time of machine failure\n",
    "def avg_temp_failure():\n",
    "    return df[df['fail'] == 1]['Temperature'].mean()\n",
    "\n",
    "\n",
    "# 6. Likelihood of failure with high VOC levels\n",
    "def failure_with_high_voc(voc_threshold):\n",
    "    high_voc_failures = df[(df['VOC'] > voc_threshold) & (df['fail'] == 1)]\n",
    "    total_high_voc = df[df['VOC'] > voc_threshold]\n",
    "    if len(total_high_voc) == 0:\n",
    "        return 0\n",
    "    return len(high_voc_failures) / len(total_high_voc) * 100\n",
    "\n",
    "# 7. Effect of footfall on machine failure rates\n",
    "def failure_rate_by_footfall(footfall_threshold):\n",
    "    high_footfall_failures = df[(df['footfall'] > footfall_threshold) & (df['fail'] == 1)]\n",
    "    total_high_footfall = df[df['footfall'] > footfall_threshold]\n",
    "    if len(total_high_footfall) == 0:\n",
    "        return 0\n",
    "    return len(high_footfall_failures) / len(total_high_footfall) * 100\n",
    "\n",
    "# 8. Failures when cooling system level is above 5\n",
    "def failures_with_high_cs(cs_threshold):\n",
    "    return len(df[(df['CS'] > cs_threshold) & (df['fail'] == 1)])\n",
    "\n",
    "# 9. Relationship between air quality (AQ) and machine failure\n",
    "def aq_failure_relation(aq_threshold):\n",
    "    poor_aq_failures = df[(df['AQ'] > aq_threshold) & (df['fail'] == 1)]\n",
    "    total_poor_aq = df[df['AQ'] > aq_threshold]\n",
    "    if len(total_poor_aq) == 0:\n",
    "        return 0\n",
    "    return len(poor_aq_failures) / len(total_poor_aq) * 100\n",
    "\n",
    "# 10. Effect of input power (IP) on failure probability\n",
    "def failure_rate_by_ip(ip_threshold):\n",
    "    high_ip_failures = df[(df['IP'] > ip_threshold) & (df['fail'] == 1)]\n",
    "    total_high_ip = df[df['IP'] > ip_threshold]\n",
    "    if len(total_high_ip) == 0:\n",
    "        return 0\n",
    "    return len(high_ip_failures) / len(total_high_ip) * 100\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd09d5c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80a3369b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Failures: 393\n",
      "Total Non-Failures: 551\n",
      "Common Failure Conditions: {'footfall': 0, 'tempMode': 7, 'AQ': 6, 'USS': 2, 'CS': 6, 'VOC': 6, 'RP': 38, 'IP': 6, 'Temperature': 21, 'fail': 1}\n",
      "Average Temperature at Failure: 17.68\n",
      "Failure Rate with High VOC (>50): 0.00%\n",
      "Failure Rate by High Footfall (>200): 29.52%\n",
      "Failures with CS Level > 5: 224\n",
      "Failure Rate with Poor Air Quality (AQ > 70): 0.00%\n",
      "Failure Rate by High IP (>500): 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "print(f\"Total Failures: {total_failures()}\")\n",
    "print(f\"Total Non-Failures: {total_non_failures()}\")\n",
    "print(f\"Common Failure Conditions: {common_failure_conditions()}\")\n",
    "print(f\"Average Temperature at Failure: {avg_temp_failure():.2f}\")\n",
    "print(f\"Failure Rate with High VOC (>50): {failure_with_high_voc(50):.2f}%\")\n",
    "print(f\"Failure Rate by High Footfall (>200): {failure_rate_by_footfall(200):.2f}%\")\n",
    "print(f\"Failures with CS Level > 5: {failures_with_high_cs(5)}\")\n",
    "print(f\"Failure Rate with Poor Air Quality (AQ > 70): {aq_failure_relation(70):.2f}%\")\n",
    "print(f\"Failure Rate by High IP (>500): {failure_rate_by_ip(500):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450cfdeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e0ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdefec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_response(user_input):\n",
    "    input_text = vectorizer.transform([user_input])\n",
    "    predicted_intent = best_model.predict(input_text)[0]\n",
    "    \n",
    "    for intent in intents['intents']:\n",
    "        if intent['tag'] == \"Total_Failures\":\n",
    "            response=total_failures()\n",
    "            break\n",
    "        elif intent['tag'] == \"Total_Non_Failures\":\n",
    "            response=total_non_failures()\n",
    "            break\n",
    "        elif intent['tag'] == \"Common_Failure_Conditions\":\n",
    "            response=common_failure_conditions()\n",
    "            break\n",
    "        elif intent['tag'] == \"Average_Temperature\":\n",
    "            response=avg_temp_failure()\n",
    "            break\n",
    "        elif intent['tag'] == \"High_VOC\":\n",
    "            response=failure_with_high_voc(50)\n",
    "            break\n",
    "        elif intent['tag'] == \"High_Footfall\":\n",
    "            response=failure_rate_by_footfall(200)\n",
    "            break\n",
    "        elif intent['tag'] == \"CS_Level\":\n",
    "            response=failures_with_high_cs(5)\n",
    "            break\n",
    "        elif intent['tag'] == \"Poor_Air_Quality\":\n",
    "            response=aq_failure_relation(70)\n",
    "            break\n",
    "        elif intent['tag'] == \"High_IP\":\n",
    "            response=failure_rate_by_ip(500)\n",
    "            break\n",
    "        elif intent['tag'] == predicted_intent:\n",
    "            response = random.choice(intent['responses'])\n",
    "            break\n",
    "            \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e53224f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello!\n"
     ]
    }
   ],
   "source": [
    "user_input='hello'\n",
    "response = chatbot_response(user_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d0296df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393\n"
     ]
    }
   ],
   "source": [
    "user_input='Total Failures'\n",
    "response = chatbot_response(user_input)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29c91c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Train the vectorizer on the full dataset\n",
    "X_train = vectorizer.fit_transform(text_data)\n",
    "\n",
    "# Model training\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "best_model = DecisionTreeClassifier()\n",
    "best_model.fit(X_train, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6551a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I am a chatbot. How can I help you today? Type \"quit\" to exit.\n"
     ]
    }
   ],
   "source": [
    "print('Hello! I am a chatbot. How can I help you today? Type \"quit\" to exit.')\n",
    "while True:\n",
    "    user_input = input('>>> ')\n",
    "    if user_input.lower() == 'quit':\n",
    "        break\n",
    "    response = chatbot_response(user_input)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4576ab57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jarvis\n"
     ]
    }
   ],
   "source": [
    "print(\"Jarvis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34da903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "if not os.path.exists('model'):\n",
    "    os.makedirs('model')\n",
    "\n",
    "if not os.path.exists('dataset'):\n",
    "    os.makedirs('dataset')\n",
    "\n",
    "# Save the trained model\n",
    "with open('model/chatbot_model.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "# Save the vectorizer\n",
    "with open('model/vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "# Save the intents to the \"dataset\" folder\n",
    "with open('dataset/intents1.json', 'w') as f:\n",
    "    json.dump(intents, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d580219",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
